{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sparkhpc.sparkjob:Submitted batch job 666761\n",
      "\n",
      "INFO:sparkhpc.sparkjob:Submitted cluster 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import atexit\n",
    "import sys\n",
    "\n",
    "import pyspark\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "import findspark\n",
    "from sparkhpc import sparkjob\n",
    "\n",
    "#Exit handler to clean up the Spark cluster if the script exits or crashes\n",
    "def exitHandler(sj,sc):\n",
    "    try:\n",
    "        print('Trapped Exit cleaning up Spark Context')\n",
    "        sc.stop()\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        print('Trapped Exit cleaning up Spark Job')\n",
    "        sj.stop()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "#Parameters for the Spark cluster\n",
    "nodes=15\n",
    "tasks_per_node=8 \n",
    "memory_per_task=1024 #1 gig per process, adjust accordingly\n",
    "# Please estimate walltime carefully to keep unused Spark clusters from sitting \n",
    "# idle so that others may use the resources.\n",
    "walltime=\"8:00\" #1 hour\n",
    "os.environ['SBATCH_PARTITION']='lattice' #Set the appropriate ARC partition\n",
    "\n",
    "sj = sparkjob.sparkjob(\n",
    "     ncores=nodes*tasks_per_node,\n",
    "     cores_per_executor=tasks_per_node,\n",
    "     memory_per_core=memory_per_task,\n",
    "     walltime=walltime\n",
    "    )\n",
    "\n",
    "sj.wait_to_start()\n",
    "sc = sj.start_spark()\n",
    "\n",
    "#Register the exit handler                                                                                                     \n",
    "atexit.register(exitHandler,sj,sc)\n",
    "\n",
    "#You need this line if you want to use SparkSQL\n",
    "sqlCtx=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql import functions as F\n",
    "spark = SparkSession.builder.appName('dfTest').getOrCreate()\n",
    "df = spark.read.csv('Data/AirOnTimeCSV/airOT20*',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- YEAR: integer (nullable = true)\n",
      " |-- MONTH: integer (nullable = true)\n",
      " |-- DAY_OF_MONTH: integer (nullable = true)\n",
      " |-- DAY_OF_WEEK: integer (nullable = true)\n",
      " |-- FL_DATE: timestamp (nullable = true)\n",
      " |-- UNIQUE_CARRIER: string (nullable = true)\n",
      " |-- TAIL_NUM: string (nullable = true)\n",
      " |-- FL_NUM: integer (nullable = true)\n",
      " |-- ORIGIN_AIRPORT_ID: integer (nullable = true)\n",
      " |-- ORIGIN: string (nullable = true)\n",
      " |-- ORIGIN_STATE_ABR: string (nullable = true)\n",
      " |-- DEST_AIRPORT_ID: integer (nullable = true)\n",
      " |-- DEST: string (nullable = true)\n",
      " |-- DEST_STATE_ABR: string (nullable = true)\n",
      " |-- CRS_DEP_TIME: integer (nullable = true)\n",
      " |-- DEP_TIME: integer (nullable = true)\n",
      " |-- DEP_DELAY: double (nullable = true)\n",
      " |-- DEP_DELAY_NEW: double (nullable = true)\n",
      " |-- DEP_DEL15: double (nullable = true)\n",
      " |-- DEP_DELAY_GROUP: integer (nullable = true)\n",
      " |-- TAXI_OUT: double (nullable = true)\n",
      " |-- WHEELS_OFF: string (nullable = true)\n",
      " |-- WHEELS_ON: string (nullable = true)\n",
      " |-- TAXI_IN: double (nullable = true)\n",
      " |-- CRS_ARR_TIME: integer (nullable = true)\n",
      " |-- ARR_TIME: integer (nullable = true)\n",
      " |-- ARR_DELAY: double (nullable = true)\n",
      " |-- ARR_DELAY_NEW: double (nullable = true)\n",
      " |-- ARR_DEL15: double (nullable = true)\n",
      " |-- ARR_DELAY_GROUP: integer (nullable = true)\n",
      " |-- CANCELLED: double (nullable = true)\n",
      " |-- CANCELLATION_CODE: string (nullable = true)\n",
      " |-- DIVERTED: double (nullable = true)\n",
      " |-- CRS_ELAPSED_TIME: double (nullable = true)\n",
      " |-- ACTUAL_ELAPSED_TIME: double (nullable = true)\n",
      " |-- AIR_TIME: double (nullable = true)\n",
      " |-- FLIGHTS: double (nullable = true)\n",
      " |-- DISTANCE: double (nullable = true)\n",
      " |-- DISTANCE_GROUP: integer (nullable = true)\n",
      " |-- CARRIER_DELAY: double (nullable = true)\n",
      " |-- WEATHER_DELAY: double (nullable = true)\n",
      " |-- NAS_DELAY: double (nullable = true)\n",
      " |-- SECURITY_DELAY: double (nullable = true)\n",
      " |-- LATE_AIRCRAFT_DELAY: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# remove empty last column and print schema\n",
    "df = df.select(df.columns[:44])\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------------+-----------+-------------------+--------------+--------+------+-----------------+------+----------------+---------------+----+--------------+------------+--------+---------+-------------+---------+---------------+--------+----------+---------+-------+------------+--------+---------+-------------+---------+---------------+---------+-----------------+--------+----------------+-------------------+--------+-------+--------+--------------+-------------+-------------+---------+--------------+-------------------+\n",
      "|YEAR|MONTH|DAY_OF_MONTH|DAY_OF_WEEK|            FL_DATE|UNIQUE_CARRIER|TAIL_NUM|FL_NUM|ORIGIN_AIRPORT_ID|ORIGIN|ORIGIN_STATE_ABR|DEST_AIRPORT_ID|DEST|DEST_STATE_ABR|CRS_DEP_TIME|DEP_TIME|DEP_DELAY|DEP_DELAY_NEW|DEP_DEL15|DEP_DELAY_GROUP|TAXI_OUT|WHEELS_OFF|WHEELS_ON|TAXI_IN|CRS_ARR_TIME|ARR_TIME|ARR_DELAY|ARR_DELAY_NEW|ARR_DEL15|ARR_DELAY_GROUP|CANCELLED|CANCELLATION_CODE|DIVERTED|CRS_ELAPSED_TIME|ACTUAL_ELAPSED_TIME|AIR_TIME|FLIGHTS|DISTANCE|DISTANCE_GROUP|CARRIER_DELAY|WEATHER_DELAY|NAS_DELAY|SECURITY_DELAY|LATE_AIRCRAFT_DELAY|\n",
      "+----+-----+------------+-----------+-------------------+--------------+--------+------+-----------------+------+----------------+---------------+----+--------------+------------+--------+---------+-------------+---------+---------------+--------+----------+---------+-------+------------+--------+---------+-------------+---------+---------------+---------+-----------------+--------+----------------+-------------------+--------+-------+--------+--------------+-------------+-------------+---------+--------------+-------------------+\n",
      "|2006|    8|           1|          2|2006-08-01 00:00:00|            AA|  N588AA|   346|            12266|   IAH|              TX|          13930| ORD|            IL|        1546|    1645|     59.0|         59.0|      1.0|              3|    12.0|      1657|     1913|    4.0|        1830|    1917|     47.0|         47.0|      1.0|              3|      0.0|             null|     0.0|           164.0|              152.0|   136.0|    1.0|   925.0|             4|          0.0|          0.0|      0.0|           0.0|               47.0|\n",
      "|2006|    8|           2|          3|2006-08-02 00:00:00|            AA|  N479AA|   346|            12266|   IAH|              TX|          13930| ORD|            IL|        1546|    1543|     -3.0|          0.0|      0.0|             -1|    17.0|      1600|     1828|   31.0|        1830|    1859|     29.0|         29.0|      1.0|              1|      0.0|             null|     0.0|           164.0|              196.0|   148.0|    1.0|   925.0|             4|          0.0|          0.0|     29.0|           0.0|                0.0|\n",
      "|2006|    8|           3|          4|2006-08-03 00:00:00|            AA|  N4WVAA|   346|            12266|   IAH|              TX|          13930| ORD|            IL|        1546|    1652|     66.0|         66.0|      1.0|              4|    16.0|      1708|     1922|   14.0|        1830|    1936|     66.0|         66.0|      1.0|              4|      0.0|             null|     0.0|           164.0|              164.0|   134.0|    1.0|   925.0|             4|          0.0|          2.0|      0.0|           0.0|               64.0|\n",
      "|2006|    8|           4|          5|2006-08-04 00:00:00|            AA|  N4UBAA|   346|            12266|   IAH|              TX|          13930| ORD|            IL|        1546|    1546|      0.0|          0.0|      0.0|              0|    20.0|      1606|     1815|    9.0|        1830|    1824|     -6.0|          0.0|      0.0|             -1|      0.0|             null|     0.0|           164.0|              158.0|   129.0|    1.0|   925.0|             4|         null|         null|     null|          null|               null|\n",
      "|2006|    8|           5|          6|2006-08-05 00:00:00|            AA|  N461AA|   346|            12266|   IAH|              TX|          13930| ORD|            IL|        1554|    1730|     96.0|         96.0|      1.0|              6|    12.0|      1742|     1946|    8.0|        1840|    1954|     74.0|         74.0|      1.0|              4|      0.0|             null|     0.0|           166.0|              144.0|   124.0|    1.0|   925.0|             4|          0.0|          0.0|      0.0|           0.0|               74.0|\n",
      "+----+-----+------------+-----------+-------------------+--------------+--------+------+-----------------+------+----------------+---------------+----+--------------+------------+--------+---------+-------------+---------+---------------+--------+----------+---------+-------+------------+--------+---------+-------------+---------+---------------+---------+-----------------+--------+----------------+-------------------+--------+-------+--------+--------------+-------------+-------------+---------+--------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# limit to just flights out of Houston (IAH)\n",
    "houstondf = df.where(df.ORIGIN == \"IAH\")\n",
    "houstondf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84370143\n",
      "2306830\n"
     ]
    }
   ],
   "source": [
    "print(df.count())\n",
    "print(houstondf.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the one null value entry where CRS_DEP_TIME is Null\n",
    "# Does nothing on this dataset... it happens in 2012 from AUS, TX, not IAH, TX\n",
    "#cleandf = houstondf.where(~F.isnull(df.CRS_DEP_TIME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For now...\n",
    "cleandf = houstondf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(cleandf.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Labels and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create label column\n",
    "# 3-CANCELLED\n",
    "# 2-DIVERTED\n",
    "# 1-ARR_DEL15\n",
    "# 0-ON_TIME (to 15 mins late)\n",
    "# -1-OTHER (shouldn't be any others)\n",
    "\n",
    "lfdf = cleandf.withColumn(\"LABEL\", when(cleandf.CANCELLED > 0.5, 3)\\\n",
    "                   .otherwise(when(cleandf.DIVERTED > 0.5, 2)\\\n",
    "                             .otherwise(when(cleandf.ARR_DEL15 > 0.5, 1)\\\n",
    "                                       .otherwise(when(cleandf.ARR_DEL15 < 0.5, 0)\\\n",
    "                                                  .otherwise(-1)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----------+--------------+------+----+--------------+------------+--------+-----+\n",
      "|YEAR|MONTH|DAY_OF_WEEK|UNIQUE_CARRIER|ORIGIN|DEST|DEST_STATE_ABR|CRS_DEP_TIME|DISTANCE|LABEL|\n",
      "+----+-----+-----------+--------------+------+----+--------------+------------+--------+-----+\n",
      "|2006|    8|          2|            AA|   IAH| ORD|            IL|        1546|   925.0|    1|\n",
      "|2006|    8|          3|            AA|   IAH| ORD|            IL|        1546|   925.0|    1|\n",
      "|2006|    8|          4|            AA|   IAH| ORD|            IL|        1546|   925.0|    1|\n",
      "|2006|    8|          5|            AA|   IAH| ORD|            IL|        1546|   925.0|    0|\n",
      "|2006|    8|          6|            AA|   IAH| ORD|            IL|        1554|   925.0|    1|\n",
      "+----+-----+-----------+--------------+------+----+--------------+------------+--------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select features and label\n",
    "# removed ORIGIN and ORIGIN_STATE_ABR because they are all the same now that it is just Houston (IAH)\n",
    "lfdf = lfdf.select(\"YEAR\", \"MONTH\", \"DAY_OF_WEEK\", \"UNIQUE_CARRIER\", \"ORIGIN\",\\\n",
    "               \"DEST\", \"DEST_STATE_ABR\", \"CRS_DEP_TIME\", \"DISTANCE\", \"LABEL\")\n",
    "lfdf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2306830\n"
     ]
    }
   ],
   "source": [
    "# check number of data points\n",
    "print(lfdf.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----------+--------------+------+----+--------------+------------+--------+-----+\n",
      "|YEAR|MONTH|DAY_OF_WEEK|UNIQUE_CARRIER|ORIGIN|DEST|DEST_STATE_ABR|CRS_DEP_TIME|DISTANCE|LABEL|\n",
      "+----+-----+-----------+--------------+------+----+--------------+------------+--------+-----+\n",
      "|2010|    7|          4|            9E|   IAH| MEM|            TN|        1155|   469.0|    0|\n",
      "|2010|    7|          5|            9E|   IAH| MEM|            TN|        1155|   469.0|    1|\n",
      "|2010|    7|          6|            9E|   IAH| MEM|            TN|        1155|   469.0|    0|\n",
      "|2010|    7|          7|            9E|   IAH| MEM|            TN|        1155|   469.0|    0|\n",
      "|2010|    7|          1|            9E|   IAH| MEM|            TN|        1155|   469.0|    3|\n",
      "|2010|    7|          2|            9E|   IAH| MEM|            TN|        1155|   469.0|    0|\n",
      "|2010|    7|          3|            9E|   IAH| MEM|            TN|        1155|   469.0|    1|\n",
      "|2010|    7|          4|            9E|   IAH| MEM|            TN|        1155|   469.0|    0|\n",
      "|2010|    7|          5|            9E|   IAH| MEM|            TN|        1155|   469.0|    0|\n",
      "|2010|    7|          6|            9E|   IAH| MEM|            TN|        1155|   469.0|    0|\n",
      "+----+-----+-----------+--------------+------+----+--------------+------------+--------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# take only the last 3 years of data so it can be processed on just one machine\n",
    "lfdf = lfdf.where(lfdf.YEAR > 2009)\n",
    "lfdf.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of data points\n",
    "print(lfdf.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeaturesLabels201006.csv\n",
      "FeaturesLabels201007.csv\n",
      "FeaturesLabels201008.csv\n",
      "FeaturesLabels201009.csv\n",
      "FeaturesLabels201010.csv\n",
      "FeaturesLabels201011.csv\n",
      "FeaturesLabels201012.csv\n"
     ]
    }
   ],
   "source": [
    "# save features and label in files\n",
    "years = [2010]\n",
    "#years = [2012-x for x in range (25)] # list of years in reverse.\n",
    "months = [x for x in range(6, 13)]\n",
    "\n",
    "for year in years:\n",
    "    for month in months:\n",
    "        filename = \"FeaturesLabels\" + str(year) + \"{:02d}\".format(month) + \".csv\"\n",
    "        print(filename)\n",
    "        lfdf.where((lfdf.YEAR == year) & (lfdf.MONTH == month)).toPandas().to_csv(\"./Data/preprocR1-1/arrDel_cancelled_diverted_onTime_Houston/\"+filename, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for NULL values and Nan values in original data\n",
    "#df.select([F.count(when(F.isnan(c), c)).alias(c) for c in df.columns]).show()\n",
    "df.select([F.count(when(F.isnull(c), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check for NULL values and Nan values in feature and label data\n",
    "#lfdf.select([F.count(when(F.isnan(c), c)).alias(c) for c in lfdf.columns]).show() # no nans in this dataset\n",
    "lfdf.select([F.count(when(F.isnull(c), c)).alias(c) for c in lfdf.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## investigate ORIGIN_STATE_ABR\n",
    "since we are reducing the data to just those flights leaving from Houston (IAH), we will be removing this column. Don't need to investigate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## investigate CRS_ELAPSED_TIME null values\n",
    "This one is tricky...\n",
    "\n",
    "It is not just in early records or just for diverted flights...\n",
    "\n",
    "Maybe calculate it from CRS_DEP_TIME and CRS_ARR_TIME? or remove column?\n",
    "\n",
    "Decided to remove the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test3 = df.where(F.isnull(df.CRS_ELAPSED_TIME))\n",
    "test3.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test4 = test3.select(\"YEAR\").distinct()\n",
    "test4.show()\n",
    "test5 = test3.select(\"DIVERTED\").distinct()\n",
    "test5.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## investigate DEST_STATE_ABR null values\n",
    "They only exist in the very early data (YEAR = 1987-1990). Do not need to worry about it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = df.where(F.isnull(df.DEST_STATE_ABR))\n",
    "test2 = test1.select(\"YEAR\").distinct()\n",
    "test2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## investigate CRS_DEP_TIME null value\n",
    "There is only one. so we can just remove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(F.isnull(df.CRS_DEP_TIME)).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
