{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data\n",
    "- Remove unnecessary columns\n",
    "- Remove flights without any delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob \n",
    "import os\n",
    "\n",
    "#Read in data\n",
    "df = pd.concat(map(pd.read_csv, glob.glob(os.path.join('2012/', \"*.csv\"))))\n",
    "\n",
    "#Remove unnecessary columns\n",
    "df = df[['YEAR', 'MONTH', 'DAY_OF_WEEK', 'UNIQUE_CARRIER', \n",
    "                 'ORIGIN', 'ORIGIN_STATE_ABR','DEST', 'DEST_STATE_ABR', \n",
    "                 'CRS_DEP_TIME','CRS_ARR_TIME','DISTANCE', 'CARRIER_DELAY',\n",
    "                 'WEATHER_DELAY', 'NAS_DELAY', 'SECURITY_DELAY', 'LATE_AIRCRAFT_DELAY']]\n",
    "\n",
    "#Remove all na values which indicate that flights are on-time or cancelled\n",
    "lateFlights = df.dropna()\n",
    "\n",
    "#Remove all flights that do not leave from IAH airport\n",
    "flightDataHouston = lateFlights[lateFlights['ORIGIN']=='IAH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the dataframe for single label analysis\n",
    "singleLabel = flightDataHouston.copy()\n",
    "singleLabel['MAX_DELAY'] = singleLabel[['CARRIER_DELAY','WEATHER_DELAY','NAS_DELAY', 'SECURITY_DELAY', 'LATE_AIRCRAFT_DELAY']].idxmax(axis=1)\n",
    "singleLabel.head()\n",
    "\n",
    "#Remove unnecessary label columns\n",
    "singleLabel = singleLabel.drop(['ORIGIN', 'ORIGIN_STATE_ABR', 'CARRIER_DELAY','WEATHER_DELAY','NAS_DELAY', 'SECURITY_DELAY', 'LATE_AIRCRAFT_DELAY'], axis=1)\n",
    "singleLabel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframe for multilabel analysis\n",
    "multiLabel = flightDataHouston.copy()\n",
    "multiLabel['CARRIER_DELAY'] = np.where(multiLabel['CARRIER_DELAY']>=1, 1, 0)\n",
    "multiLabel['WEATHER_DELAY'] = np.where(multiLabel['WEATHER_DELAY']>=1, 1, 0)\n",
    "multiLabel['NAS_DELAY'] = np.where(multiLabel['NAS_DELAY']>=1, 1, 0)\n",
    "multiLabel['SECURITY_DELAY'] = np.where(multiLabel['SECURITY_DELAY']>=1, 1, 0)\n",
    "multiLabel['LATE_AIRCRAFT_DELAY'] = np.where(multiLabel['LATE_AIRCRAFT_DELAY']>=1, 1, 0)\n",
    "\n",
    "multiLabel.head()\n",
    "#Remove unnecessary columns\n",
    "multiLabel = multiLabel.drop(['ORIGIN', 'ORIGIN_STATE_ABR'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform one-hot-encoding for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete one hot encoding for single label analysis\n",
    "#print(singleLabel.head())\n",
    "singleLabel = pd.get_dummies(singleLabel, columns=['UNIQUE_CARRIER'], prefix = ['UNIQUE_CARRIER'])\n",
    "singleLabel = pd.get_dummies(singleLabel, columns=['DEST'], prefix = ['DEST'])\n",
    "singleLabel = pd.get_dummies(singleLabel, columns=['DEST_STATE_ABR'], prefix = ['DEST_STATE_ABR'])\n",
    "singleLabel = pd.get_dummies(singleLabel, columns=['DAY_OF_WEEK'], prefix = ['DAY_OF_WEEK'])\n",
    "singleLabel = pd.get_dummies(singleLabel, columns=['MONTH'], prefix = ['MONTH'])\n",
    "\n",
    "#Complete one hot encoding for multilabel analysis\n",
    "multiLabel = pd.get_dummies(multiLabel, columns=['UNIQUE_CARRIER'], prefix = ['UNIQUE_CARRIER'])\n",
    "multiLabel = pd.get_dummies(multiLabel, columns=['DEST'], prefix = ['DEST'])\n",
    "multiLabel = pd.get_dummies(multiLabel, columns=['DEST_STATE_ABR'], prefix = ['DEST_STATE_ABR'])\n",
    "multiLabel = pd.get_dummies(multiLabel, columns=['DAY_OF_WEEK'], prefix = ['DAY_OF_WEEK'])\n",
    "multiLabel = pd.get_dummies(multiLabel, columns=['MONTH'], prefix = ['MONTH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single Label Test/Train Sets\n",
    "single_features = singleLabel.drop('MAX_DELAY', axis = 'columns')\n",
    "single_label = singleLabel.MAX_DELAY\n",
    "\n",
    "#Multi Label Test/Train Sets\n",
    "multi_features = multiLabel.drop(['CARRIER_DELAY', 'WEATHER_DELAY', 'NAS_DELAY', 'SECURITY_DELAY', 'LATE_AIRCRAFT_DELAY'], axis = 'columns')\n",
    "multi_label = multiLabel[['CARRIER_DELAY','WEATHER_DELAY', 'NAS_DELAY', 'SECURITY_DELAY', 'LATE_AIRCRAFT_DELAY']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Testing and Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Set up train and test split for single label analysis\n",
    "x_train_single, x_test_single, y_train_single, y_test_single = train_test_split(single_features,single_label,test_size=0.3, shuffle = True)\n",
    "#Set up train and test split for multi label analysis\n",
    "x_train_multi, x_test_multi, y_train_multi, y_test_multi = train_test_split(multi_features,multi_label,test_size=0.3, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model One vs Rest Logistical Regression Multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "#printmd('**bold**')\n",
    "\n",
    "\n",
    "# Using pipeline for applying logistic regression and one vs rest classifier\n",
    "LogReg_pipeline = Pipeline([\n",
    "                ('clf', OneVsRestClassifier(LogisticRegression(solver='sag',max_iter=4000), n_jobs=-1)),\n",
    "            ])\n",
    "\n",
    "for label in multi_label:\n",
    "    printmd('**Processing {} comments...**'.format(label))\n",
    "    \n",
    "    # Training logistic regression model on train data\n",
    "    LogReg_pipeline.fit(x_train_multi, y_train_multi[label])\n",
    "    \n",
    "    # calculating test accuracy\n",
    "    prediction = LogReg_pipeline.predict(x_test_multi)\n",
    "    print('Test accuracy is {}'.format(accuracy_score(y_test_multi[label], prediction)))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"Confusion Matrix\")\n",
    "    print(confusion_matrix(y_test_multi[label], prediction))\n",
    "    print('\\n')\n",
    "\n",
    "    print(\"Classification Report\")\n",
    "    print(classification_report(y_test_multi[label], prediction))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Single Output Logistical Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(x_train_single, y_train_single)\n",
    "lgr_predict = logisticRegr.predict(x_test_single)\n",
    "\n",
    "print(\"Accuracy Score\")\n",
    "print(accuracy_score(y_test_single, lgr_predict))\n",
    "print('\\n')\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test_single, lgr_predict))\n",
    "print('\\n')\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test_single, lgr_predict))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Single Output Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(x_train_single, y_train_single)\n",
    "rfc_predict = model.predict(x_test_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"Accuracy Score\")\n",
    "print(accuracy_score(y_test_single, rfc_predict))\n",
    "print('\\n')\n",
    "\n",
    "rfc_predict = model.predict(x_test_single)\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test_single, rfc_predict))\n",
    "print('\\n')\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test_single, rfc_predict))\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numerical feature importances\n",
    "importances = list(model.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_list = list(single_features.columns)\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-run Random Forest Classifier using Extracted Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "singleLabel_simp = flightDataHouston.copy()\n",
    "singleLabel_simp['MAX_DELAY'] = singleLabel_simp[['CARRIER_DELAY','WEATHER_DELAY','NAS_DELAY', 'SECURITY_DELAY', 'LATE_AIRCRAFT_DELAY']].idxmax(axis=1)\n",
    "\n",
    "#Remove unnecessary label columns\n",
    "singleLabel_simp = singleLabel_simp.drop(['ORIGIN','ORIGIN_STATE_ABR','CARRIER_DELAY','WEATHER_DELAY','NAS_DELAY', 'SECURITY_DELAY', 'LATE_AIRCRAFT_DELAY', 'DAY_OF_WEEK', 'UNIQUE_CARRIER', 'DEST', 'DEST_STATE_ABR', 'DISTANCE'], axis=1)\n",
    "singleLabel_simp.head()\n",
    "\n",
    "#Complete one hot encoding for single label analysis\n",
    "singleLabelOneHot = pd.get_dummies(singleLabel_simp, columns=['MONTH'], prefix = ['MONTH'])\n",
    "\n",
    "#Single Label Test/Train Sets\n",
    "single_features = singleLabelOneHot.drop('MAX_DELAY', axis = 'columns')\n",
    "single_label = singleLabelOneHot.MAX_DELAY\n",
    "\n",
    "#Set up train and test split for single label analysis\n",
    "x_train_single, x_test_single, y_train_single, y_test_single = train_test_split(single_features,single_label,test_size=0.3, shuffle = True)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(x_train_single, y_train_single)\n",
    "\n",
    "rfc_predict = model.predict(x_test_single)\n",
    "\n",
    "print(\"Accuracy Score\")\n",
    "print(accuracy_score(y_test_single, rfc_predict))\n",
    "print('\\n')\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test_single, rfc_predict))\n",
    "print('\\n')\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test_single, rfc_predict))\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
